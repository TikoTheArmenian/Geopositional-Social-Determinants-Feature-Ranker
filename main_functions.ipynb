{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mutual_info_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from rankers import *\n",
    "from hyper_param_search import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   person_id   hdl    ldl   trig    sbp   dbp        bmi    HR  egfr  cre_alb  \\\n0    2825659  45.0   64.0  156.0  109.0  71.0  25.840000  76.0   NaN      NaN   \n1    1769136  43.0   77.0  350.0  146.0  86.0  25.299999  72.0  60.0      NaN   \n2    2582132  45.0   74.0  171.0  172.0  60.0  30.820000  62.0  18.0      NaN   \n3    2966613  36.0  115.0  128.0  116.0  86.0        NaN  75.0  99.0      NaN   \n4    2323362  43.0   75.0  166.0  133.0  76.0  29.860000  55.0   NaN      NaN   \n\n   ...  no_health_insurance    poverty  vacant_housing deprivation_index  \\\n0  ...             7.192906   9.716275        5.911106          0.225707   \n1  ...             2.828384   8.649236        6.690513          0.247603   \n2  ...             6.863952  17.753432       11.598508          0.314289   \n3  ...             2.948661   9.679384        6.108289          0.251716   \n4  ...            10.278120  14.373649        6.069094          0.291387   \n\n   mi_status t2d_status  mace_status hf_status  scd_status  stroke_status  \n0          1          0            1         0           0              0  \n1          1          0            1         1           0              0  \n2          0          1            0         0           0              0  \n3          0          0            0         0           0              0  \n4          0          1            0         0           0              0  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>person_id</th>\n      <th>hdl</th>\n      <th>ldl</th>\n      <th>trig</th>\n      <th>sbp</th>\n      <th>dbp</th>\n      <th>bmi</th>\n      <th>HR</th>\n      <th>egfr</th>\n      <th>cre_alb</th>\n      <th>...</th>\n      <th>no_health_insurance</th>\n      <th>poverty</th>\n      <th>vacant_housing</th>\n      <th>deprivation_index</th>\n      <th>mi_status</th>\n      <th>t2d_status</th>\n      <th>mace_status</th>\n      <th>hf_status</th>\n      <th>scd_status</th>\n      <th>stroke_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2825659</td>\n      <td>45.0</td>\n      <td>64.0</td>\n      <td>156.0</td>\n      <td>109.0</td>\n      <td>71.0</td>\n      <td>25.840000</td>\n      <td>76.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>7.192906</td>\n      <td>9.716275</td>\n      <td>5.911106</td>\n      <td>0.225707</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1769136</td>\n      <td>43.0</td>\n      <td>77.0</td>\n      <td>350.0</td>\n      <td>146.0</td>\n      <td>86.0</td>\n      <td>25.299999</td>\n      <td>72.0</td>\n      <td>60.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.828384</td>\n      <td>8.649236</td>\n      <td>6.690513</td>\n      <td>0.247603</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2582132</td>\n      <td>45.0</td>\n      <td>74.0</td>\n      <td>171.0</td>\n      <td>172.0</td>\n      <td>60.0</td>\n      <td>30.820000</td>\n      <td>62.0</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>6.863952</td>\n      <td>17.753432</td>\n      <td>11.598508</td>\n      <td>0.314289</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2966613</td>\n      <td>36.0</td>\n      <td>115.0</td>\n      <td>128.0</td>\n      <td>116.0</td>\n      <td>86.0</td>\n      <td>NaN</td>\n      <td>75.0</td>\n      <td>99.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.948661</td>\n      <td>9.679384</td>\n      <td>6.108289</td>\n      <td>0.251716</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2323362</td>\n      <td>43.0</td>\n      <td>75.0</td>\n      <td>166.0</td>\n      <td>133.0</td>\n      <td>76.0</td>\n      <td>29.860000</td>\n      <td>55.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>10.278120</td>\n      <td>14.373649</td>\n      <td>6.069094</td>\n      <td>0.291387</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './mena_ml_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "def view_data(df_full):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and prints the percentage of NaN values in each column.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    None: This function doesn't return anything; it prints to the console.\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for column in df_full.columns:\n",
    "        # Count the number of NaN values in the current column\n",
    "        nan_count = df_full[column].isna().sum()\n",
    "\n",
    "        # Calculate the percentage of NaN values in the current column\n",
    "        nan_percentage = round(nan_count / len(df_full) * 100, 1)\n",
    "\n",
    "        # Print the percentage of NaN values for the current column\n",
    "        print(f'The column {column} has {nan_percentage}% NaN values.')\n",
    "\n",
    "\n",
    "def get_data(df_full, thresh=0.8,\n",
    "             columns_to_drop=['person_id', 'egfr', 'cre_alb', 'statins_status',\n",
    "                              'antihts_status', 'race', 'race_concept_id','t2d_status',\n",
    "                              'mace_status','hf_status','scd_status','stroke_status'],\n",
    "             labels=['mi_status']):\n",
    "\n",
    "    # Separate the labels early on\n",
    "    y = df_full[labels]\n",
    "\n",
    "    # Drop specified columns\n",
    "    df_clean = df_full.drop(columns=columns_to_drop + labels)\n",
    "\n",
    "    # Calculate the threshold for the minimum number of non-missing values\n",
    "    threshold = thresh * len(df_clean)\n",
    "\n",
    "    # Drop columns with more than 20% missing values\n",
    "    df_clean = df_clean.dropna(axis=1, thresh=threshold)\n",
    "\n",
    "    # Drop rows with any missing values\n",
    "    combined = pd.concat([df_clean, y], axis=1)  # combine to make sure rows are consistent\n",
    "    combined_clean = combined.dropna()\n",
    "    df_clean = combined_clean[df_clean.columns]\n",
    "    y = combined_clean[labels]\n",
    "\n",
    "    # Initialize the Label Encoder\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Identify columns that need to be encoded (those of type 'object')\n",
    "    columns_to_encode = df_clean.select_dtypes(include=['object', 'string']).columns\n",
    "\n",
    "    # Apply Label Encoder to each categorical string column\n",
    "    for column in columns_to_encode:\n",
    "        df_clean[column] = le.fit_transform(df_clean[column])\n",
    "\n",
    "    # Separate the cleaned DataFrame into features (X) and labels (y)\n",
    "    X = df_clean\n",
    "\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "X, y = get_data(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[206], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m hypers \u001B[38;5;241m=\u001B[39m \u001B[43mclassification_hyper_param_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m hypers\n",
      "File \u001B[1;32m~\\Desktop\\Research\\Gleghorn\\Feature_ranker\\hyper_param_search.py:86\u001B[0m, in \u001B[0;36mclassification_hyper_param_search\u001B[1;34m(X, y, cv, num_runs, model_params)\u001B[0m\n\u001B[0;32m     84\u001B[0m     acc \u001B[38;5;241m=\u001B[39m accuracy_score(y, predictions)\n\u001B[0;32m     85\u001B[0m     cm \u001B[38;5;241m=\u001B[39m confusion_matrix(y, predictions)\n\u001B[1;32m---> 86\u001B[0m     \u001B[43mplot_confusion_matrix\u001B[49m(cm, title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(acc,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m3\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, labels\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39munique(y))\n\u001B[0;32m     87\u001B[0m total_hypers\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m: model_name, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest_score\u001B[39m\u001B[38;5;124m'\u001B[39m: clf\u001B[38;5;241m.\u001B[39mbest_score_, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest_params\u001B[39m\u001B[38;5;124m'\u001B[39m: clf\u001B[38;5;241m.\u001B[39mbest_params_})\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m total_hypers\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plot_confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "hypers = classification_hyper_param_search(X, y, 3, 1)\n",
    "hypers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_estimators': 889, 'max_features': 'log2', 'max_depth': 778}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_hyper = dict(rf_scores['best_params'].iloc[0])\n",
    "xb_hyper = dict(xb_scores['best_params'].iloc[0])\n",
    "rf_hyper"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "data": {
      "text/plain": "Finding C Step:   0%|          | 0/30 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfa5e3e36af640c29242cb0fcd6c3ed5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Ranking l1 Classification:   0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5fce731cf51743a1b54dded054926985"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranking = classification_ranking(X, y, rf_hyper, xb_hyper)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "                       RF     Score                     XG     Score  \\\n0                     age  0.121631          median_income  0.220408   \n1                     ldl  0.121471                poverty  0.124953   \n2                    trig  0.091473                   trig  0.090837   \n3                     sbp  0.085195                    ldl  0.081631   \n4                     bmi  0.077955               zip_code  0.069088   \n5                     hdl  0.075046        assisted_income  0.059192   \n6                     dbp  0.068696      deprivation_index  0.055863   \n7                      HR  0.058193                    sbp  0.052083   \n8                zip_code  0.043575  high_school_education  0.046118   \n9     no_health_insurance  0.038478                     HR  0.042916   \n10         vacant_housing  0.036697                    bmi  0.041680   \n11          median_income  0.035965    no_health_insurance  0.037316   \n12  high_school_education  0.034031                    age  0.034890   \n13        assisted_income  0.031818                    dbp  0.030392   \n14      deprivation_index  0.031560                    hdl  0.006895   \n15                poverty  0.029705         vacant_housing  0.005041   \n16           sex_at_birth  0.018513           sex_at_birth  0.000699   \n17         smoking_status  0.000000         smoking_status  0.000000   \n\n                       MI     Score                      F      Score  \\\n0                     age  0.021554                    age  50.090692   \n1                    trig  0.021496           sex_at_birth  19.674834   \n2                     ldl  0.020969                    ldl  18.447975   \n3            sex_at_birth  0.014419                    hdl  14.986263   \n4                     hdl  0.011021                   trig  14.357639   \n5                zip_code  0.010966                    dbp   6.366412   \n6           median_income  0.008230                     HR   3.024215   \n7     no_health_insurance  0.006513                    sbp   0.439655   \n8          smoking_status  0.005207                    bmi   0.341425   \n9                     bmi  0.002352    no_health_insurance   0.279309   \n10      deprivation_index  0.001815         vacant_housing   0.068715   \n11                    dbp  0.001250               zip_code   0.060107   \n12                    sbp  0.000074        assisted_income   0.025768   \n13                     HR  0.000000      deprivation_index   0.016521   \n14        assisted_income  0.000000  high_school_education   0.011374   \n15  high_school_education  0.000000          median_income   0.006777   \n16                poverty  0.000000                poverty   0.004886   \n17         vacant_housing  0.000000         smoking_status   0.000000   \n\n                       L1   Score  \n0                     age   0.019  \n1                     ldl   0.033  \n2            sex_at_birth   0.033  \n3                     hdl   0.037  \n4                    trig   0.042  \n5                     dbp   0.055  \n6                     sbp   0.131  \n7                zip_code   0.141  \n8           median_income   0.217  \n9                      HR   0.344  \n10    no_health_insurance   0.449  \n11                    bmi   0.619  \n12  high_school_education   0.706  \n13         vacant_housing   1.043  \n14        assisted_income   1.065  \n15                poverty   6.055  \n16      deprivation_index  10.000  \n17         smoking_status  10.000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RF</th>\n      <th>Score</th>\n      <th>XG</th>\n      <th>Score</th>\n      <th>MI</th>\n      <th>Score</th>\n      <th>F</th>\n      <th>Score</th>\n      <th>L1</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>age</td>\n      <td>0.121631</td>\n      <td>median_income</td>\n      <td>0.220408</td>\n      <td>age</td>\n      <td>0.021554</td>\n      <td>age</td>\n      <td>50.090692</td>\n      <td>age</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ldl</td>\n      <td>0.121471</td>\n      <td>poverty</td>\n      <td>0.124953</td>\n      <td>trig</td>\n      <td>0.021496</td>\n      <td>sex_at_birth</td>\n      <td>19.674834</td>\n      <td>ldl</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>trig</td>\n      <td>0.091473</td>\n      <td>trig</td>\n      <td>0.090837</td>\n      <td>ldl</td>\n      <td>0.020969</td>\n      <td>ldl</td>\n      <td>18.447975</td>\n      <td>sex_at_birth</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sbp</td>\n      <td>0.085195</td>\n      <td>ldl</td>\n      <td>0.081631</td>\n      <td>sex_at_birth</td>\n      <td>0.014419</td>\n      <td>hdl</td>\n      <td>14.986263</td>\n      <td>hdl</td>\n      <td>0.037</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bmi</td>\n      <td>0.077955</td>\n      <td>zip_code</td>\n      <td>0.069088</td>\n      <td>hdl</td>\n      <td>0.011021</td>\n      <td>trig</td>\n      <td>14.357639</td>\n      <td>trig</td>\n      <td>0.042</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>hdl</td>\n      <td>0.075046</td>\n      <td>assisted_income</td>\n      <td>0.059192</td>\n      <td>zip_code</td>\n      <td>0.010966</td>\n      <td>dbp</td>\n      <td>6.366412</td>\n      <td>dbp</td>\n      <td>0.055</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dbp</td>\n      <td>0.068696</td>\n      <td>deprivation_index</td>\n      <td>0.055863</td>\n      <td>median_income</td>\n      <td>0.008230</td>\n      <td>HR</td>\n      <td>3.024215</td>\n      <td>sbp</td>\n      <td>0.131</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>HR</td>\n      <td>0.058193</td>\n      <td>sbp</td>\n      <td>0.052083</td>\n      <td>no_health_insurance</td>\n      <td>0.006513</td>\n      <td>sbp</td>\n      <td>0.439655</td>\n      <td>zip_code</td>\n      <td>0.141</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>zip_code</td>\n      <td>0.043575</td>\n      <td>high_school_education</td>\n      <td>0.046118</td>\n      <td>smoking_status</td>\n      <td>0.005207</td>\n      <td>bmi</td>\n      <td>0.341425</td>\n      <td>median_income</td>\n      <td>0.217</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>no_health_insurance</td>\n      <td>0.038478</td>\n      <td>HR</td>\n      <td>0.042916</td>\n      <td>bmi</td>\n      <td>0.002352</td>\n      <td>no_health_insurance</td>\n      <td>0.279309</td>\n      <td>HR</td>\n      <td>0.344</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>vacant_housing</td>\n      <td>0.036697</td>\n      <td>bmi</td>\n      <td>0.041680</td>\n      <td>deprivation_index</td>\n      <td>0.001815</td>\n      <td>vacant_housing</td>\n      <td>0.068715</td>\n      <td>no_health_insurance</td>\n      <td>0.449</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>median_income</td>\n      <td>0.035965</td>\n      <td>no_health_insurance</td>\n      <td>0.037316</td>\n      <td>dbp</td>\n      <td>0.001250</td>\n      <td>zip_code</td>\n      <td>0.060107</td>\n      <td>bmi</td>\n      <td>0.619</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>high_school_education</td>\n      <td>0.034031</td>\n      <td>age</td>\n      <td>0.034890</td>\n      <td>sbp</td>\n      <td>0.000074</td>\n      <td>assisted_income</td>\n      <td>0.025768</td>\n      <td>high_school_education</td>\n      <td>0.706</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>assisted_income</td>\n      <td>0.031818</td>\n      <td>dbp</td>\n      <td>0.030392</td>\n      <td>HR</td>\n      <td>0.000000</td>\n      <td>deprivation_index</td>\n      <td>0.016521</td>\n      <td>vacant_housing</td>\n      <td>1.043</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>deprivation_index</td>\n      <td>0.031560</td>\n      <td>hdl</td>\n      <td>0.006895</td>\n      <td>assisted_income</td>\n      <td>0.000000</td>\n      <td>high_school_education</td>\n      <td>0.011374</td>\n      <td>assisted_income</td>\n      <td>1.065</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>poverty</td>\n      <td>0.029705</td>\n      <td>vacant_housing</td>\n      <td>0.005041</td>\n      <td>high_school_education</td>\n      <td>0.000000</td>\n      <td>median_income</td>\n      <td>0.006777</td>\n      <td>poverty</td>\n      <td>6.055</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>sex_at_birth</td>\n      <td>0.018513</td>\n      <td>sex_at_birth</td>\n      <td>0.000699</td>\n      <td>poverty</td>\n      <td>0.000000</td>\n      <td>poverty</td>\n      <td>0.004886</td>\n      <td>deprivation_index</td>\n      <td>10.000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>smoking_status</td>\n      <td>0.000000</td>\n      <td>smoking_status</td>\n      <td>0.000000</td>\n      <td>vacant_housing</td>\n      <td>0.000000</td>\n      <td>smoking_status</td>\n      <td>0.000000</td>\n      <td>smoking_status</td>\n      <td>10.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def voting(df):\n",
    "    \"\"\"\n",
    "    Aggregate feature rankings for each target variable using a weighted voting mechanism.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): A DataFrame containing feature rankings from different models for each target column.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing final feature rankings for each target variable.\n",
    "    \"\"\"\n",
    "    # Get the unique target variables in the DataFrame\n",
    "    unique_targets = df['target_col'].unique()\n",
    "\n",
    "    # Initialize an empty dictionary to hold the final rankings for each target\n",
    "    all_scores = {}\n",
    "\n",
    "    # Loop through each unique target variable\n",
    "    for target in unique_targets:\n",
    "        # Initialize an empty dictionary to hold the scores for the current target\n",
    "        final_scores = {}\n",
    "\n",
    "        # Get rows that correspond to the current target variable\n",
    "        rows = df[df['target_col'] == target]\n",
    "\n",
    "        # Extract the ordered lists of features for each model\n",
    "        lasso = rows['Lasso order'].tolist()\n",
    "        rf = rows['RF order'].tolist()\n",
    "        xgb = rows['XGB order'].tolist()\n",
    "        rfe = rows['RFE order'].tolist()\n",
    "        mi = rows['MI order'].tolist()\n",
    "\n",
    "        # Define the weights for each model\n",
    "        w1, w2, w3, w4, w5 = 0.3, 0.2, 0.2, 0.1, 0.1\n",
    "\n",
    "        # Pair each feature list with its corresponding weight\n",
    "        lists_and_weights = [(lasso, w1), (rf, w2), (xgb, w3), (rfe, w4), (mi, w5)]\n",
    "\n",
    "        # Calculate the final scores\n",
    "        for feature_list, weight in lists_and_weights:\n",
    "            for i, feature in enumerate(reversed(feature_list)):\n",
    "                if feature not in final_scores:\n",
    "                    final_scores[feature] = 0\n",
    "                final_scores[feature] += (i + 1) * weight\n",
    "\n",
    "        # Sort features by their final scores in descending order\n",
    "        final_ranking = sorted(final_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        # Store the final ranking for the current target in the 'all_scores' dictionary\n",
    "        all_scores[target] = final_ranking\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, race in tqdm(enumerate(races)):\n",
    "    hypers = hyper_param_search(Xs[i], ys[i], 5, model_params, 20)\n",
    "\n",
    "    xb_scores = hypers[hypers['model'] == 'XGBoost'].reset_index(drop=True)\n",
    "    rf_scores = hypers[hypers['model'] == 'random_forest'].reset_index(drop=True)\n",
    "    xb_scores.to_csv(f'xb_hypers_social_det_{race}.csv', index=False)\n",
    "    rf_scores.to_csv(f'rf_hypers_social_det_{race}.csv', index=False)\n",
    "\n",
    "    ranks = classification_ranking(Xs[i], ys[i], rf_scores, xb_scores, 1)\n",
    "\n",
    "    scoring = voting(ranks)\n",
    "\n",
    "    for key in list(scoring.keys()):\n",
    "        # Split the features and scores\n",
    "        features, scores = zip(*scoring[key])\n",
    "        height_per_feature = 0.5\n",
    "        fig_height = len(features) * height_per_feature\n",
    "\n",
    "        # Create a figure and a set of subplots\n",
    "        fig, ax = plt.subplots(figsize=(10, fig_height))\n",
    "        fig.patch.set_facecolor('white')\n",
    "\n",
    "        # Plot a horizontal bar chart\n",
    "        ax.barh(features, scores, color='blue', alpha=0.6)\n",
    "        # Invert the y-axis to have the highest score at the top\n",
    "        ax.invert_yaxis()\n",
    "        # Set labels for the x-axis and the plot with a white background\n",
    "        label_opts = {'color': 'black', 'bbox': dict(facecolor='white', edgecolor='none')}\n",
    "        ax.set_xlabel('Scores', **label_opts)\n",
    "        ax.set_ylabel('Features', **label_opts)\n",
    "        ax.set_title(f'Ranking of Features for {key} in {race}')\n",
    "\n",
    "        # Apply background color to tick labels\n",
    "        ax.tick_params(axis='both', which='both', labelsize='large', labelcolor='black', colors='black')\n",
    "\n",
    "        # Save and show the plot with all elements included\n",
    "        plt.savefig(f'feature_{key}_{race}_rank.png', bbox_inches='tight', transparent=False, dpi=300)\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def sanitize_column_names(df):\n",
    "    \"\"\"\n",
    "    Sanitize column names by replacing prohibited characters.\n",
    "    \"\"\"\n",
    "    sanitized_columns = [col.replace(\"[\", \"_\").replace(\"]\", \"_\").replace(\"<\", \"_\") for col in df.columns]\n",
    "    df.columns = sanitized_columns\n",
    "    return df\n",
    "\n",
    "# Use the function before training\n",
    "X_train = sanitize_column_names(X_train)\n",
    "X_test = sanitize_column_names(X_test)\n",
    "\n",
    "cls = xgb.XGBClassifier(use_label_encoder=False, eval_metric='error')\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ensure both y_test and y_pred are 1D arrays\n",
    "y_test = np.array(y_test).ravel()\n",
    "y_pred = np.array(y_pred).ravel()\n",
    "\n",
    "# Report classification accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Report other classification metrics (precision, recall, F1-score, etc.)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues',\n",
    "            xticklabels=['Below 40', '40-80', 'Above 80'],\n",
    "            yticklabels=['Below 40', '40-80', 'Above 80'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title(f'Confusion Matrix\\nAccuracy: {accuracy:.3f}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ensure both y_test and y_pred are 1D arrays\n",
    "y_test = np.array(y_test).ravel()\n",
    "y_pred = np.array(y_pred).ravel()\n",
    "\n",
    "# 5. Report the Pearson correlation\n",
    "corr, _ = pearsonr(y_test, y_pred)\n",
    "print(f'Pearson correlation: {corr:.3f}')\n",
    "\n",
    "# Report the R^2 score\n",
    "r2 = best_ridge.score(X_test, y_test)\n",
    "print(f'R^2 score: {r2:.3f}')\n",
    "\n",
    "# 6. Plot the predicted values against the true labels\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title(f'True vs Predicted Values\\nR^2 score: {r2:.3f}')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # diagonal line\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}